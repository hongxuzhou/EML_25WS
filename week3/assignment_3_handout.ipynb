{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec1488d",
   "metadata": {},
   "source": [
    "# Assignment 3 - Generalization, Regularization and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64025e0",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "This assignment is worth a total of **10 points**. The goal of this assignment is to introduce you to selecting the best model using k fold cross validation. You will also explore methods for selecting hyperparameters for regularization to enhance the generalizability of your trained models.\n",
    "\n",
    "We have structured the assignment into two parts:\n",
    "\n",
    "1. **Part One**: Generalization\n",
    "2. **Part Two**: Regularization and Model Selection\n",
    "\n",
    "To ensure you understand how each package is used, libraries will be imported as and when needed. The libraries used are all open source, and if you do not have any of these libraries installed, you can install them using the `pip install` method, either via your terminal or within a code cell in this notebook. For example, in your code cell you can use:\n",
    "\n",
    "`!pip install matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1fb373",
   "metadata": {},
   "source": [
    "# Part Zero: Common definitions\n",
    "\n",
    "There is no task for you to complete in this part. This only provides you with some predefined things.\n",
    "\n",
    "You're not required to understand everything here, but you should read the documentation to understand how to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db14b49",
   "metadata": {},
   "source": [
    "In the lectures up to now, we only talked about linear models.\n",
    "\n",
    "Polynomial regression is very similar. We have\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + ... + \\varepsilon\n",
    "$$\n",
    "and we treat $[x, x^2, ...]$ as predictors and transform it to linear regression with $\\beta_1, \\beta_2, ...$ as coefficients and $\\beta_0$ as intercept. And rest follows the linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cb9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "def make_poly_model(degree: int, reg: Literal[\"\", \"Lasso\", \"Ridge\"] = \"\", lambd: float = 0.0) -> Pipeline:\n",
    "    \"\"\"Make a polynomial regression model of given degree.\n",
    "\n",
    "    Parameters:\n",
    "    degree: the polynomial degree.\n",
    "    reg: selects the regularization.\n",
    "    lambd: the lambda of regularization, ignored if reg=''.\n",
    "\n",
    "    Return is a model with model.fit() and model.predict(), just like other sklearn models.\n",
    "    \"\"\"\n",
    "    match reg:\n",
    "        case \"\":\n",
    "            linear = LinearRegression()\n",
    "        case \"Lasso\":\n",
    "            linear = Lasso(lambd)\n",
    "        case \"Ridge\":\n",
    "            linear = Ridge(lambd)\n",
    "        case _:  # should not enter this case\n",
    "            assert False\n",
    "    return Pipeline([(\"poly\", PolynomialFeatures(degree=degree, include_bias=False)), (\"linear\", linear)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb19e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO = None  # Placeholder to bypass syntax error. Replace it with your code.\n",
    "\n",
    "# TODO: This kind of comment indicates missing parts you need to fill with explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e5244",
   "metadata": {},
   "source": [
    "# Part One: Generalization, <span style=\"color:green\">total of 5 points </span> \n",
    "\n",
    "\n",
    "We use a small synthetic dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_samples = 23\n",
    "X_all = np.sort(np.random.rand(num_samples) * 10).reshape(-1, 1)\n",
    "y_all = np.sin(X_all.reshape(-1)) + np.random.randn(num_samples) * 0.1\n",
    "\n",
    "samp_idx = (X_all.reshape(-1) < 4) + (X_all.reshape(-1) > 6)\n",
    "X = X_all[samp_idx]\n",
    "y = y_all[samp_idx]\n",
    "print(len(X))\n",
    "\n",
    "# Plot the synthetic data\n",
    "plt.scatter(X, y, label=\"Data\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c3e3d4",
   "metadata": {},
   "source": [
    "### k-fold Cross-Validation:\n",
    "\n",
    "### <span style=\"color:red\"> Task 1: Implement a k-fold cross-validation function as discussed in **Lecture 6** by filling in the parts of the code with TODOs. </span>\n",
    "\n",
    "\n",
    "The metrics we would use will be MSE. We will use the libraries for the metrics directly from sklearn.\n",
    "\n",
    "#### <span style=\"color:green\">Total: 1 point</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7863d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def kfold_cross_validation(model, X: np.ndarray, y: np.ndarray, k: int = 5, random_seed: int = 42):\n",
    "    \"\"\"k-fold cross-validation for a selected model.\n",
    "\n",
    "    Parameters:\n",
    "    model: The model you want to evaluate.\n",
    "    X: The input features (numpy array).\n",
    "    y: The target variable (numpy array).\n",
    "    k: Number of folds (default is 5).\n",
    "\n",
    "    Returns:\n",
    "    Average metrics across the K folds.\n",
    "    \"\"\"\n",
    "    random.seed(a=random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    n_samples = len(X)\n",
    "    assert n_samples % k == 0\n",
    "    fold_size = TODO  # TODO: calculate the foldsize\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    mses = []\n",
    "    for i in range(k):\n",
    "        test_indices = TODO  # TODO: pick out fold i\n",
    "        train_indices = TODO  # TODO: the rest of indices\n",
    "\n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # TODO: add MSE to the list\n",
    "\n",
    "    return np.mean(mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c9c35",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "### <span style=\"color:red\">Task 2:  Fit polynomial models with different degrees on your training data with your written 5-fold cross validation function above by filling in the parts of the code with TODO.</span>\n",
    "\n",
    "#### <span style=\"color:green\">Total: 1 point </span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e03f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_range = [1, 2, 3, 6, 10, 15]\n",
    "\n",
    "kfold_mse = []\n",
    "\n",
    "# Loop through different polynomial degrees\n",
    "for degree in degrees_range:\n",
    "\n",
    "    # Define the polynomial regression model\n",
    "    poly_model = TODO  # TODO: define the model without regularization\n",
    "\n",
    "    # set random seed to 42 (default) in k-fold\n",
    "    # TODO: add k-fold CV mse to the list\n",
    "\n",
    "\n",
    "# plot MSE-deg\n",
    "plt.plot(degrees_range, kfold_mse)\n",
    "plt.xlabel(\"Polynomial Degree (DoF)\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c210824",
   "metadata": {},
   "source": [
    "### Evaluating with Varying K\n",
    "\n",
    "### <span style=\"color:red\">Task 3: Write a for loop over different values of k by completing the sections of the code with TODO.\n",
    "\n",
    "\n",
    "#### <span style=\"color:green\">Total: 1 point </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41477148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of k values\n",
    "k_values = [2, 5, 10, 20]\n",
    "\n",
    "# Loop through different polynomial degrees\n",
    "for degree in degrees_range:\n",
    "    # TODO: define the mse list\n",
    "\n",
    "    # Perform cross-validation for each value of k\n",
    "    for k in k_values:\n",
    "        # Define the polynomial regression model\n",
    "        poly_model = TODO  # TODO: define the model without regularization\n",
    "\n",
    "        # set random seed to 42 (default) in k-fold\n",
    "        # TODO: add k-fold CV mse to the list\n",
    "\n",
    "    # TODO: Plot the MSE of each model (in the same plot, not subplots)\n",
    "\n",
    "# Show plot\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE vs. k\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba69647b",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Task 3.1: Based on the output of your code, which model is the best? Does the k value affect the selection of the models?\n",
    "\n",
    "\n",
    "#### <span style=\"color:green\">Total: 1 point </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86add3ad",
   "metadata": {},
   "source": [
    "**TODO**: fill your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cff881",
   "metadata": {},
   "source": [
    "## Part Two: Regularization and Model Selection, <span style=\"color:green\">total of 6 points </span> \n",
    "\n",
    "In this section, we will fix the degree of the polynomial and explore different regularization methods, namely Lasso and Ridge, along with different tuning parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d099bf05",
   "metadata": {},
   "source": [
    "### Regularization Terms\n",
    "\n",
    "### <span style=\"color:red\"> Task 4: Implement regularization terms as discussed in **Lecture 7** by filling in the parts of the code with TODOs. </span>\n",
    "\n",
    "\n",
    "Here you should calculate the terms added to loss (with $\\lambda$) from the parameters.\n",
    "\n",
    "#### <span style=\"color:green\">Total: 1 point</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9083f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1(model, lambd: float) -> float:\n",
    "    # parameters in the linear regression\n",
    "    betas = model.named_steps[\"linear\"].coef_\n",
    "    beta0 = model.named_steps[\"linear\"].intercept_\n",
    "    return TODO  # TODO: calculate for L1 term (for Lasso)\n",
    "\n",
    "\n",
    "def l2(model, lambd: float) -> float:\n",
    "    # parameters in the linear regression\n",
    "    betas = model.named_steps[\"linear\"].coef_\n",
    "    beta0 = model.named_steps[\"linear\"].intercept_\n",
    "    return TODO  # TODO: calculate for L2 term (for Ridge)\n",
    "\n",
    "\n",
    "# poly_model is carried from the previous task. It should be deterministic if you run all cell in order.\n",
    "print(\"L1: \", l1(poly_model, 1))\n",
    "print(\"L2: \", l2(poly_model, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78128999",
   "metadata": {},
   "source": [
    "#### Lasso & Ridge Regression\n",
    "\n",
    "### <span style=\"color:red\">Task 5: Fill in the missing parts of the code to evaluate ridge and lasso regression using different lambda values. Use the 10-fold CV implemented above </span>\n",
    "\n",
    "#### <span style=\"color:green\">Total: 1 point </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afaa83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values = np.concat([np.logspace(-6, 6, 13)])\n",
    "mse_lasso = []\n",
    "mse_ridge = []\n",
    "degree = 10\n",
    "\n",
    "# Loop through different polynomial degrees\n",
    "for lambd in lambda_values:\n",
    "\n",
    "    # Define the polynomial regression model\n",
    "    lasso = TODO\n",
    "    ridge = TODO  # TODO: define the two models with Lasso and Ridge respectively\n",
    "\n",
    "    # set random seed to 42 (default) in k-fold\n",
    "    # TODO: add the k-fold CV mse to respective list\n",
    "\n",
    "\n",
    "# plot MSE-deg\n",
    "plt.plot(lambda_values, mse_lasso, label=\"Lasso\")\n",
    "plt.plot(lambda_values, mse_ridge, label=\"Ridge\")\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# print min\n",
    "print(f\"Best lambda for Lasso {TODO}\")\n",
    "print(f\"Best lambda for Ridge {TODO}\")  # TODO: find the best lambda for both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f00830",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Task 5.1: Based on the output of your code, which regularization is the better? And what is the optimal lambda?\n",
    "\n",
    "\n",
    "#### <span style=\"color:green\">Total: 1 point </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586e75b",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Task 6: Choose the model of with the best regularization you found above by filling in the TODO, and run the visualization. </span>\n",
    "\n",
    "#### <span style=\"color:green\">Total: 0.5 point </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5650ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = np.linspace(X_all.min(), X_all.max(), 100).reshape(-1, 1)\n",
    "degree = 10\n",
    "\n",
    "\n",
    "model = TODO  # TODO: define the model without regularization\n",
    "reg_model = TODO  # TODO: define the model with the best regularization you found\n",
    "\n",
    "\n",
    "model.fit(X, y)\n",
    "reg_model.fit(X, y)\n",
    "\n",
    "\n",
    "pred = model.predict(X)\n",
    "reg_pred = reg_model.predict(X)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X, y, label=\"Data\")\n",
    "plt.plot(X_plot, model.predict(X_plot), label=f\"W/o regularizaion, MSE={TODO}\")  # TODO: calc the MSE of both predictions\n",
    "plt.plot(X_plot, reg_model.predict(X_plot), label=f\"W/ regularizaion, MSE={TODO}\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(f\"Predictions on data in CV\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylim(-1.6, 1.3)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "pred = model.predict(X_all)\n",
    "reg_pred = reg_model.predict(X_all)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_all, y_all, label=\"Data\")\n",
    "plt.plot(X_plot, model.predict(X_plot), label=f\"W/o regularizaion, MSE={TODO}\")  # TODO: calc the MSE of both predictions\n",
    "plt.plot(X_plot, reg_model.predict(X_plot), label=f\"W/ regularizaion, MSE={TODO}\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(f\"Predictions on data unseen from CV\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylim(-1.6, 1.3)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93920725",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Task 6.1: Look at the plots above. Does regularization seem to be helpful in each graph? Explain why there's difference.\n",
    "\n",
    "\n",
    "#### <span style=\"color:green\">Total: 2.5 points </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eefb3ab-6caf-4861-951d-3f143d48b20e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "\n",
    "\n",
    "## That is it for this assignment, we do hope you learn something from this exercise!\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py314",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
